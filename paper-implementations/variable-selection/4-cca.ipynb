{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonical correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://davetang.github.io/muse/cca.html:\n",
    "\n",
    "Canonical Correlation Analysis (CCA) is a dimension reduction technique like Principal Component Analysis (PCA). PCA aims to find the directions or projections that account for most of the observed variance. In comparison, CCA deals with two datasets and aims to find directions or projections that account for most of co-variance between two data sets.\n",
    "\n",
    "To try to understand the intuition behind CCA, imagine there is one or more variables generating two high-dimensional data sets $X$ and $Y$. Here, the data sets $X$\n",
    " and $Y$ are observables and we don’t know the latent variable(s) behind the two data sets. By performing CCA, we can identify the canonical variates that are highly correlated to the unknown latent variable. Basically, CCA helps us remove the noise in the two datasets and gets to the canonical variable that captures the hidden variable.\n",
    "\n",
    " Canonical covariates are essentially the linear combinations of variables from each of the two datasets (X and Y) in Canonical Correlation Analysis (CCA). These covariates (also called canonical variates) are what CCA tries to find, and they are designed to maximize the correlation between the two sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets must correspond to the same records (observations or individuals). So, one trick is that we can split the original dataset into 2 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonical covariates (also called canonical variates) are **linear combinations** of variables from two datasets, **X** and **Y**, in Canonical Correlation Analysis (CCA). CCA finds these combinations to **maximize the correlation** between the two sets.\n",
    "\n",
    "- **U** is a linear combination of variables from **X**.\n",
    "- **V** is a linear combination of variables from **Y**.\n",
    "- CCA finds **U** and **V** so that they are as correlated as possible.\n",
    "\n",
    "After finding the first pair of canonical covariates, CCA looks for subsequent pairs that are maximally correlated but uncorrelated with the previous pairs. This process helps reveal the **best linear relationships** between the two datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a talk at UChicago Stats Dept: \n",
    "\n",
    "Claire Donnat\n",
    "\n",
    "Department of Statistics\n",
    "\n",
    "University of Chicago\n",
    "\n",
    "“Practical Canonical Correlation Analysis in High-Dimensions”\n",
    "\n",
    "While the last decade has seen a proliferation of sparse CCA methods, practical challenges regarding the scalability and adaptability of these \n",
    "methods still persist. To circumvent these issues, in this talk, we explore an alternative strategy \n",
    "that uses reduced rank regression to estimate the canonical directions. The first part of the talk will \n",
    "focus on the case when one of the datasets is high-dimensional while the other remains low-dimensional, before extending our method to the setting where both datasets are high-dimensional in the second part of this talk. **By casting the problem of estimating the canonical direction as a \n",
    "regression problem, our estimators are able to leverage the rich statistics literature on high-dimensional regression and is easily adaptable to accommodate a wider range of structural priors**. Our proposed solutions maintain computational efficiency and accuracy, even in the presence of \n",
    "very high-dimensional data. We validate the benefits of our approach through a series of simulated \n",
    "experiments and further showcase its practicality on two use cases"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
